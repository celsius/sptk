% ----------------------------------------------------------------- %
%             The Speech Signal Processing Toolkit (SPTK)           %
%             developed by SPTK Working Group                       %
%             http://sp-tk.sourceforge.net/                         %
% ----------------------------------------------------------------- %
%                                                                   %
%  Copyright (c) 1984-2007  Tokyo Institute of Technology           %
%                           Interdisciplinary Graduate School of    %
%                           Science and Engineering                 %
%                                                                   %
%                1996-2010  Nagoya Institute of Technology          %
%                           Department of Computer Science          %
%                                                                   %
% All rights reserved.                                              %
%                                                                   %
% Redistribution and use in source and binary forms, with or        %
% without modification, are permitted provided that the following   %
% conditions are met:                                               %
%                                                                   %
% - Redistributions of source code must retain the above copyright  %
%   notice, this list of conditions and the following disclaimer.   %
% - Redistributions in binary form must reproduce the above         %
%   copyright notice, this list of conditions and the following     %
%   disclaimer in the documentation and/or other materials provided %
%   with the distribution.                                          %
% - Neither the name of the SPTK working group nor the names of its %
%   contributors may be used to endorse or promote products derived %
%   from this software without specific prior written permission.   %
%                                                                   %
% THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND            %
% CONTRIBUTORS "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES,       %
% INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF          %
% MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE          %
% DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS %
% BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,          %
% EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED   %
% TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,     %
% DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON %
% ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,   %
% OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY    %
% OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE           %
% POSSIBILITY OF SUCH DAMAGE.                                       %
% ----------------------------------------------------------------- %
\hypertarget{pitch}{}
\name{pitch}{pitch extraction}{signal processing,speech analysis and synthesis}

\begin{synopsis}
\item[pitch] [ --s $S$ ] [ --l $L$ ] [ --t $T$ ]
 [ --L $Lo$ ] [ --H $Hi$ ] [ --e $E$ ]
\item[\ ~~~~~] [ --i $I$ ] [ --j $J$ ] [ --d $D$ ] [ {\em infile} ] 
\end{synopsis}

\begin{qsection}{DESCRIPTION}
{\em pitch} uses the cepstrum method to calculate the pitch period values
corresponding to frames of input data of length $L$ 
from {\em infile} (or standard input), 
sending the result to standard output. 
For unvoiced frames, the output value is 0.0. 
For voiced frames, the output value is proportional to the pitch period.

Input and output data are in float format.

To discriminate between voiced and unvoiced sounds,
the unbiased estimation of log spectrum method is applied
to evaluate $(S/10 \times 25)$-th order cepstrum.
Then from these coefficients, the magnitude of log spectrum
$\hat{g}_i(\Omega_k)$ is evaluated.
Finally the mean value $v_i$ for every band is calculated.
\begin{displaymath}
v_i = \frac{1}{14 n}\sum_{k = 4 n}^{17 n}\hat{g}_i(\Omega_k),\qquad (\Omega_k = \frac{2 \pi k}{N},n = N /256)
\end{displaymath}

Here the FFT size $N$ is square number greater then $L$.

If the speech sound is voiced $(v_i > T)$,
then the FFT cepstral coefficients $c(m)$ are transformed
into $c(m) \times m$,
and the peak frequency between $Lo$ (Hz) and $Hi$ (Hz)
is the pitch.
If the speech sound is unvoiced $(v_i < T)$
then $0$ is output.

\end{qsection}

\begin{options}
	\argm{s}{S}{sampling frequency (kHz)}{10}
	\argm{l}{L}{frame length}{400}
	\argm{t}{T}{voiced/unvoiced threshold}{6.0}
	\argm{L}{Lo}{minimum fundamental
                     frequency to search for (Hz)}{60}
	\argm{H}{Hi}{minimum fundamental
                     frequency to search for (Hz)}{240}
	\argm{e}{E}{small value for calculate
                    log-spectral envelope}{0.0}
        \desc[1ex]{Usually, the options below do not need to be assigned.}
	\argm{i}{I}{minimum number of iteration}{2}
	\argm{j}{J}{maximum number of iteration}{30}
	\argm{d}{D}{end condition}{0.1}
\end{options}

\begin{qsection}{EXAMPLE}
Speech data with sampling rate 10kHz is read in float format
from {\em data.f}, the pitch is evaluated, and
the output is written to {\em data.pitch}:
\begin{quote}
  \verb!frame +f -l 400 < data.f | window -l 400 |\ !\\
  \verb!pitch -l 400 > data.pitch!
\end{quote}
\end{qsection}

\begin{qsection}{SEE ALSO}
\hyperlink{excite}{excite}
\end{qsection}
